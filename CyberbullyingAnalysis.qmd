---
title: "CyberbullyingAnalysis"
format: html
editor: visual
---

## Setup

```{r setup}
library(tidyverse)
library(tidymodels)
library(tidytext)

data <- read.csv("https://raw.githubusercontent.com/agmath/agmath.github.io/refs/heads/master/data/classification/cyberbullying_tweets.csv")

data |>
  count(cyberbullying_type)

data <- data |>
  distinct()

set.seed(19032025)

data_split <- initial_split(data, prop = 0.9)
train <- training(data_split)
test <- testing(data_split)
```



```{r head}
data |>
  head()
```

## Tokenization

```{r isolating words}
common_words_list <- train |>
  mutate(tweet_id = row_number()) |>
  unnest_tokens(word, tweet_text) |>
  anti_join(stop_words) |>
  filter(!(word %in% c("http", "https", "t.co", "bully", "bullies", "bullied"))) |>
  filter(!str_starts(word, "\\d+")) |>
  count(word) |>
  arrange(-n) |>
  filter(n >= 100) |>
  pull(word)


train |>
  mutate(tweet_id = row_number()) |>
  unnest_tokens(word, tweet_text) |>
  anti_join(stop_words) |>
  filter(!(word %in% c("http", "https", "t.co", "bully", "bullies", "bullied"))) |>
  filter(!str_starts(word, "\\d+")) |>
  filter(word %in% common_words_list) |>
  distinct() |> 
  slice(1:1e4) |> 
  mutate(
    present = 1
  ) |>
  pivot_wider(id_cols = c(cyberbullying_type, tweet_id),
              names_from = word,
              values_from = present)
```

## Data Viz

```{r}
train |>
  mutate(tweet_id = row_number()) |>
  unnest_tokens(word, tweet_text) |>
  anti_join(stop_words) |>
  filter(!(word %in% c("http", "https", "t.co", "bully", "bullies", "bullied"))) |>
  filter(!str_starts(word, "\\d+")) |>
  group_by(cyberbullying_type) |>
  count(word) |>
  top_n(15, n) |>
  ungroup() |>
  ggplot() +
  geom_bar(aes(x = word, y = n, fill = cyberbullying_type),
           stat = "identity", color = "black",
           show.legend = FALSE) +
  facet_wrap(~cyberbullying_type, scales = "free") +
  coord_flip()
```

